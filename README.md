# cuDNN__TensorRT

<img width="1405" alt="4c879e2cf44a544951f7c92662ba561" src="https://user-images.githubusercontent.com/38579506/174629442-2644089b-658c-4aed-b784-a8833560bb83.png">



## Main Learning Goal

1. Master the analysis, development, debugging and optimization methods of CUDA parallel computing system
2. Familiar with the basic concepts of CUDA and mainstream parallel operations
3. Understand cuDNN and TensorRT, two mainstream tools for deep learning model acceleration
4. Have the ability to accelerate the acceleration of deep learning models with hands-on practice

## Chapter 1: CUDA C Programming and GPU Basics
- Section 1: GPU Basic Architecture and Features
- Section 2: CUDA C programming basics
- Section 3: Parallel Computing Vector Addition
- Section 4: Practice

## Chapter 2: CUDA C Programming: Matrix Multiplication
- Section 1: Why matrix multiplication is suitable for GPU implementation
- Section 2: GPU-based implementation of matrix multiplication
- Section 3: Advanced GPU Implementation of Matrix Multiplication
- Section 4: Code Practice
- Section 5: Homework Questions

## Chapter 3: cuda streams and Events
- Section 1: Introduction to CUDA Stream
- Section 2: Why CUDA Stream works
- Section 3: CUDA Stream default stream performance
- Section 4: CUDA Events
- Section 5: CUDA Synchronous Operations
- Section 6: NVP Tool Demonstration

## Chapter 4: cuDNN and cuBLAS
- Session 1: Course Review
- Section 2: cuBLAS
- Section 3: cuDNN
- Section 4: Practice

## Chapter 5: Introduction to TensorRT
- Section 1: What is TensorRT
- Section 2: TensorRT overall workflow and optimization strategy
- Section 3: The composition and basic usage process of TensorRT
- Section 4: TensorRT demo: SampleMNIST
- Section 5: TensorRT Advanced
- Section 6: Demo

## Chapter 6: TensorRT plugin usage
- Section 1: Introduction to Plugin
- Section 2: Static Shape Plugin
- Section 3: Dynamic Shape Plugin
- Section 4: PluginCreatori Master Book
- Section 5: Extension: How to debug TensorRT

## Chapter 7: TensorRT Quantization Acceleration
- Section 1: TRT FP16 optimization
- Section 2: TRT INT8 quantization algorithm
- Section 3: TRT large-scale launch experience


<img width="1040" alt="7f9d8e2968eaccd933679d3d73039e3" src="https://user-images.githubusercontent.com/38579506/174629645-a19acf9d-3797-44ab-a6a5-1636edbbf46d.png">

